<!DOCTYPE html>
<html lang="en">
<head>
  
    <title>The Little Book Review: No Bullshit Deep Learning 101 :: Cmbbq&#39;s Encyclopedia</title>
  
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="正如ddia可被视为分布式系统方向的入门教程，lbdl是理想的深度学习101。" />
<meta name="keywords" content="" />
<meta name="robots" content="noodp" />
<link rel="canonical" href="https://cmbbq.github.io/posts/wipthe-little-book-review-no-bullshit-deep-learning-101wip/" />




<link rel="stylesheet" href="https://cmbbq.github.io/assets/style.css">

  <link rel="stylesheet" href="https://cmbbq.github.io/assets/green.css">






<link rel="apple-touch-icon" href="https://cmbbq.github.io/img/apple-touch-icon-192x192.png">

  <link rel="shortcut icon" href="https://cmbbq.github.io/img/favicon/green.png">



<meta name="twitter:card" content="summary" />



<meta property="og:locale" content="en" />
<meta property="og:type" content="article" />
<meta property="og:title" content="The Little Book Review: No Bullshit Deep Learning 101">
<meta property="og:description" content="正如ddia可被视为分布式系统方向的入门教程，lbdl是理想的深度学习101。" />
<meta property="og:url" content="https://cmbbq.github.io/posts/wipthe-little-book-review-no-bullshit-deep-learning-101wip/" />
<meta property="og:site_name" content="Cmbbq&#39;s Encyclopedia" />

  
    <meta property="og:image" content="https://cmbbq.github.io/img/favicon/green.png">
  

<meta property="og:image:width" content="2048">
<meta property="og:image:height" content="1024">


  <meta property="article:published_time" content="2023-11-27 00:00:00 &#43;0000 UTC" />












</head>
<body class="green">


<div class="container center headings--one-size">

  <header class="header">
  <div class="header__inner">
    <div class="header__logo">
      <a href="/">
  <div class="logo">
    Cmbbq&#39;s Encyclopedia
  </div>
</a>

    </div>
    
  </div>
  
</header>


  <div class="content">
    
<div class="post">
  <h1 class="post-title">
    <a href="https://cmbbq.github.io/posts/wipthe-little-book-review-no-bullshit-deep-learning-101wip/">The Little Book Review: No Bullshit Deep Learning 101</a></h1>
  <div class="post-meta">
    
      <span class="post-date">
        2023-11-27
        
      </span>
    
    
    
  </div>

  
  <span class="post-tags">
    
    #<a href="https://cmbbq.github.io/tags/sys/">sys</a>&nbsp;
    
  </span>
  
  


  

  <div class="post-content"><div>
        <p>[WIP]</p>
<p>&ldquo;The Little Book of Deep Learning&rdquo;(<a href="https://fleuret.org/francois/lbdl.html">lbdl</a>)是日内瓦大学CS教授François Fleuret写的一本适配手机屏的书，精简扼要地面向stem背景读者介绍深度学习。正如ddia可被视为分布式系统方向的入门教程，lbdl是理想的深度学习101。</p>
<p>精简，或者说压缩，正是深度模型的strength，也是这个信息过载时代的virtue。用A4纸打印这个小册子，读起来非常舒适。</p>
<!-- raw HTML omitted -->
<hr>
<p>接下来是知识内化和梳理。</p>
<h2 id="概述">概述<a href="#概述" class="hanchor" ariaLabel="Anchor">&#8983;</a> </h2>
<p>高维信号难以用规则系统分析，而深度网络则克服了这个困难，用具有大量权重的深层映射拟合出一个足够好（loss足够低）的近似函数——这个函数可以是高维信号到连续向量（回归）或离散值（分类）的映射，也可以是一种概率密度函数，总之，它能从数据分布中学习到某种紧凑且有区分能力的表征。</p>
<p>若数据样本不足，即使训练数据上表现良好，也可能在真实应用中效果不佳，这就是过拟合。
若模型能力不足，无法适应多变场景、准确捕捉输入输出的关系，训练时loss就高，则是欠拟合。</p>
<p>机器学习模型可以粗粒度地分为3类：</p>
<ol>
<li>回归模型：有监督，训练数据是输入信号和ground-truth数值的pairs，将高维信号映射到某个向量。</li>
<li>分类模型：有监督，训练数据是输入信号和标签的pairs，将高维信号映射到有限标签集上。</li>
<li>概率密度函数模型：无监督，训练数据就是输入信号本身。</li>
</ol>
<h2 id="训练">训练<a href="#训练" class="hanchor" ariaLabel="Anchor">&#8983;</a> </h2>
<h3 id="损失函数">损失函数<a href="#损失函数" class="hanchor" ariaLabel="Anchor">&#8983;</a> </h3>
<p>所谓训练，就是降低训练集上预测函数的损失函数（loss）的过程。</p>
<p>损失函数如何定义？对连续数值来说，均方差是一个标准选择。对概率密度来说，则用似然值——可令loss=-Sum(f(x;w))，其中f(x;w)是各个训练样本的标准化log概率。对分类任务来说，一般用交叉熵。</p>
<p>何为交叉熵？分类模型为N个类输出N个logits（其实LLM也是这样，为vocabulary里每个token生成对应的logits，表示未标准化的log概率），logits经过softmax，得到后验概率P(Y=y|X=x)，这是裸概率，各个类的概率加起来和为1。令loss=1/N Sum(-logP(Y=y_n|X=x_n))，这个loss即为交叉熵。交叉熵最小化，则真类别的概率最大化。</p>
<p>在度量学习中，虽然预测的值是连续的，但实际监督形式是分级，因为度量学习的目标是学习出样本之间可比较的距离，比如A、B、C三个点，其中A和B是同一个人脸的不同侧面，C是另一个人，或者A和B是同一首歌的翻唱，C是另一首歌，那就要求AB之间距离小于AC。因此度量学习一般采用contrastive loss或triplet loss。</p>
<p>损失函数通常只是一个代理指标，而非实际性能指标，以分类任务为例，显然直接性能指标应该是分类错误率，只不过这个指标的梯度没有携带有效指导信息——错误率函数和模型权重是完全剥离的，知晓错误率的变化不能在训练中帮助模型减小错误率。</p>
<p>损失函数还可以被设计为依赖于模型权重，从而对模型权重进行某种约束和控制。比如权重衰减（weight decay），一种防止过拟合的正则化技术，给损失函数里增加了一项模型权重的平方和，从而惩罚大的权重数值，偏好小的数值，进而减少训练数据对模型权重取值范围的影响。这么做会使训练集上性能下降，但有利于在未见过的数据集上更好地泛化。</p>
<h3 id="自回归模型">自回归模型<a href="#自回归模型" class="hanchor" ariaLabel="Anchor">&#8983;</a> </h3>

      </div></div>

  
  
<div class="pagination">
    <div class="pagination__title">
        <span class="pagination__title-h">阅读其他博文</span>
        <hr />
    </div>
    <div class="pagination__buttons">
        
        <span class="button previous">
            <a href="https://cmbbq.github.io/posts/wipon-order/">
                <span class="button__icon">←</span>
                <span class="button__text">Order Emerges from Self-Assembly of Dissipative Structures</span>
            </a>
        </span>
        
        
        <span class="button next">
            <a href="https://cmbbq.github.io/posts/on-reasoning-abilities-of-llms/">
                <span class="button__text">Artificial Intuition: Reasoning Abilities of LLMs Today</span>
                <span class="button__icon">→</span>
            </a>
        </span>
        
    </div>
</div>

  

  
  

  
</div>

  </div>

  
    <footer class="footer">
  <div class="footer__inner">
    
      <div class="copyright">
        
    

        <span> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-envelope" viewBox="0 0 16 16">
          <path d="M0 4a2 2 0 0 1 2-2h12a2 2 0 0 1 2 2v8a2 2 0 0 1-2 2H2a2 2 0 0 1-2-2V4Zm2-1a1 1 0 0 0-1 1v.217l7 4.2 7-4.2V4a1 1 0 0 0-1-1H2Zm13 2.383-4.708 2.825L15 11.105V5.383Zm-.034 6.876-5.64-3.471L8 9.583l-1.326-.795-5.64 3.47A1 1 0 0 0 2 13h12a1 1 0 0 0 .966-.741ZM1 11.105l4.708-2.897L1 5.383v5.722Z"/>
        </svg> rpb.cmbbq@gmail.com </span>
      </div>
  </div>
</footer>

<script src="https://cmbbq.github.io/assets/main.js"></script>
<script src="https://cmbbq.github.io/assets/prism.js"></script>







  
</div>

</body>
</html>
