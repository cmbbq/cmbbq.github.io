<!DOCTYPE html>
<html lang="en">
<head>
  
    <title>Efficient ANNS at Scale :: Cmbbq&#39;s Encyclopedia</title>
  
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="如何在十亿、百亿级特征库上做高效的向量检索" />
<meta name="keywords" content="" />
<meta name="robots" content="noodp" />
<link rel="canonical" href="https://cmbbq.github.io/posts/efficient-anns-at-scale/" />





<link rel="stylesheet" href="https://cmbbq.github.io/assets/style.css">

  <link rel="stylesheet" href="https://cmbbq.github.io/assets/green.css">






<link rel="apple-touch-icon" href="https://cmbbq.github.io/img/apple-touch-icon-192x192.png">

  <link rel="shortcut icon" href="https://cmbbq.github.io/img/favicon/green.png">



<meta name="twitter:card" content="summary" />



<meta property="og:locale" content="en" />
<meta property="og:type" content="article" />
<meta property="og:title" content="Efficient ANNS at Scale">
<meta property="og:description" content="如何在十亿、百亿级特征库上做高效的向量检索" />
<meta property="og:url" content="https://cmbbq.github.io/posts/efficient-anns-at-scale/" />
<meta property="og:site_name" content="Cmbbq&#39;s Encyclopedia" />

  
    <meta property="og:image" content="https://cmbbq.github.io/img/favicon/green.png">
  

<meta property="og:image:width" content="2048">
<meta property="og:image:height" content="1024">


  <meta property="article:published_time" content="2023-09-12 00:00:00 &#43;0000 UTC" />












</head>
<body class="green">


<div class="container center headings--one-size">

  <header class="header">
  <script>
    MathJax = {
      tex: {
        inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
        displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
        processEscapes: false,
      },
      svg: {
        fontCache: 'global'
      }
    };
</script>
<script
    type="text/javascript" id="MathJax-script" async
    src="https://cdn.jsdelivr.net/npm/mathjax@4.0.0-beta.4/tex-mml-chtml.js">
</script>
    
  <div class="header__inner">
    <div class="header__logo">
      <a href="/">
  <div class="logo">
    Cmbbq&#39;s Encyclopedia
  </div>
</a>

    </div>
    
  </div>
  
</header>


  <div class="content">
    
<div class="post">
  <h1 class="post-title">
    <a href="https://cmbbq.github.io/posts/efficient-anns-at-scale/">Efficient ANNS at Scale</a></h1>
  <div class="post-meta">
    
      <span class="post-date">
        2023-09-12
        
      </span>
    
    
    
  </div>

  
  <span class="post-tags">
    
    #<a href="https://cmbbq.github.io/tags/ai/">ai</a>&nbsp;
    
    #<a href="https://cmbbq.github.io/tags/sys/">sys</a>&nbsp;
    
    #<a href="https://cmbbq.github.io/tags/perf/">perf</a>&nbsp;
    
  </span>
  
  


  

  <div class="post-content"><div>
        <p>向量检索分为KNN和ANN，KNN就是用brute-force计算出query向量和所有索引向量的相似度，取前k个。ANN则是通过近似手段加速计算，以误差换效率。</p>
<p>如何做高效的向量检索？方法有二，一是提升编码率（不仅能降低内存占用，也能加速计算，因为便于SIMD且减少访存）的量化（IVF向量量化、PQ量化、ScaNN各向异性量化、4bit量化），二是缩小搜索空间的图搜索（HNSW）。</p>
<p>如何在十亿、百亿级特征库上做向量检索？主要挑战是索引无法放入内存，因而需要考虑内存-磁盘混合方案（SPANN）。</p>
<p>本文只介绍一小部分有效且正交的技术，这些技术组合在一起可形成当前的最佳实践。其他一些古典、经典技术可以参考本文引用的论文的背景综述。</p>
<h1 id="相似度">相似度<a href="#相似度" class="hanchor" ariaLabel="Anchor">&#8983;</a> </h1>
<p>首先回顾一下什么是<strong>向量之间的相似度</strong>:</p>
<ul>
<li>对向量X和Y来说，x和y越接近，则x越大的地方y也大，x小的地方y也小，则内积越大。因此内积可用作相似度打分，不过不能抵抗尺度变化。</li>
<li>为了抵抗尺度变化，往往将内积正则化到[-1,1]，就变成了余弦相似度cosθ，θ为向量夹角，显然θ越小，向量越接近。</li>
<li>欧几里得距离正则化到[-1,1]后相当于sqrt(2-2cosθ)。可见欧式距离平方也是和余弦相似度成比的。</li>
</ul>
<p><img src="https://cmbbq.github.io/img/sim_measure.png" alt="sim_measure"></p>
<p>正则化后欧式距离、内积、cosθ三者同源，所以我们一般就用余弦相似度cosθ去度量向量/embedding之间的相似程度。除非又特殊的抵抗位置变化的需求，可采用皮尔森相关系数，皮尔森相关系数是协方差（两个变量的总体误差）的正则化，不过它同时也可以被视为将x和y中心化后的余弦相似度。</p>
<h1 id="向量量化">向量量化<a href="#向量量化" class="hanchor" ariaLabel="Anchor">&#8983;</a> </h1>
<p>量化器是D维向量 x  ∈ R^D 到 q(x) ∈ C = {c_0, c_1, &hellip; c_k-1} 的映射函数q。c_i即聚类中心centroid。
所谓密码本（codebook）就是一个lookup table，用centroid下标作为原始向量的低bit表示，密码本大小就是k。</p>
<p>向量量化本质是有损压缩，表征学习本质上也是有损压缩，一个白盒，一个黑盒，都是试图降低高维数据的编码率。</p>
<h1 id="ivf聚类倒排剪枝">IVF：聚类、倒排、剪枝<a href="#ivf聚类倒排剪枝" class="hanchor" ariaLabel="Anchor">&#8983;</a> </h1>
<p>倒排（特指IVF）是一种古老的量化技术，早期应用于<a href="https://www.robots.ox.ac.uk/~vgg/publications/2003/Sivic03/sivic03.pdf">Video Google</a>。核心思想是基于k-means聚类做向量量化。k-means聚类起源于信号处理领域，目标是把n个向量分区到k个clusters，每个向量属于离centroid最近的cluster。</p>
<p>聚类后有些边缘数据点既属于A，也属于B，那就把它同时放到A和B的centroid对应的postinglist里面去，不过重复放置会导致postinglist膨胀，为了应对这种膨胀，可采取剪枝策略，具体可参考微软的SPTAG项目和<a href="https://arxiv.org/pdf/2111.08566.pdf">SPANN论文</a>。</p>
<p>Faiss的IVFFlat就是在聚类形成centroid为term的倒排后提供检索能力，nlist为聚类数，nprobe为临近centroid探测数，nprobe=nlist时退化为暴搜。IVFFLat在检索时将query邻近的nprobe个centroid对应的所有原始向量作为搜索空间进行暴搜。由于centroid的表示方式可以简化成clusterid，所以实际上IVF也是一种量化：用一个数组存放所有的centroid向量，数组下标即可表示centroid。</p>
<h1 id="pq乘积量化">PQ：乘积量化<a href="#pq乘积量化" class="hanchor" ariaLabel="Anchor">&#8983;</a> </h1>
<p>基于聚类的量化对低维向量比较有效，但随着向量维度升高，出现误差也变高，而且这种误差不是提升聚类数目能解决的。如果把聚类数目（codebook大小）提升到2^64，训练这个聚类的开销就会高得无法接受，需要数倍于2^64的样本，内存显然也放不下。**乘积量化（PQ）**就是降维手段解决IVF量化误差的技术，<a href="https://lear.inrialpes.fr/pubs/2011/JDS11/jegou_searching_with_quantization.pdf">Jegou et al., 2011</a>以及<a href="https://arxiv.org/pdf/1908.10396.pdf">ScaNN</a>均讨论了PQ。其核心思想是对索引数据量化，将d维空间切分为M个子空间，将高维向量的误差拟合为分段的低维向量误差之和。</p>
<p>乘积量化中，IVF倒排链存的不是原始向量，而是原始向量的一种编码：</p>
<ul>
<li>求原始d维向量与高维粗聚类centroid的残差（残差的目的是中心化，让数据点分布变得更集中，使精度更好）</li>
<li>将残差向量切成M个分段，每个分段维度为d/M</li>
<li>每个分段做$k=2^n$个细聚类，n即为低维细聚类clusterid的编码长度，4bit或8bit</li>
<li>用每个分段的邻近低维细聚类centroid去量化该分段上的原始残差分段</li>
</ul>
<p>Faiss的IVFPQ就结合了IVF和PQ，IVF粗聚类是一级量化，PQ则是二级量化。一方面索引体积减小，另一方面计算上也只需要计算残差和分段细聚类centroid近邻的距离，还能SIMD加速，性能收益非常显著。不过IVFPQ的distance究竟只是一种拟合，是距离粗聚类centroid的距离加上M个分段里query残差和邻近细聚类centroid的距离总和，这种拟合可以一定程度上帮助找到近邻，但不适合用作距离，可以把IVFPQ当做粗排，结果再做一次brute-force或高精度ANN重算，得到更精确的距离。</p>
<p>ScaNN提出了各向异性量化，算是正本清源，纠正了此前就近选择centroid在数学上的错误，并且实践了4-bit量化取得非常好的效果（其实4bit量化的效果还比各向异性更大，但各向异性在理论上贡献更大）。传统的量化把数据点量化到离自己最近的聚类中心，但这么做未必是误差最低的，越平行的向量之间内积越大，越正交的向量之间内积越小，因此赋予平行向量更高的误差惩罚权重效果更好。这就意味着不一定量化到距离最近的centroid了，目标是整体编码率不变的前提下，让平行方向量化误差更小，正交方向误差高一些其实无所谓，从而提升整体的ANN效果。</p>
<p>假设d/M = 4，采用8bit量化，原始向量是256维f32向量，则PQ将256个float32压缩到64个int8，内存减少到1/16。乘积量化显然可以显著减少内存和存储开销，其实这也能加速计算，原因如下：</p>
<ul>
<li>高效点乘（其实也是误差换效率）：O(dk+mn) 比 O(nd)快，d维度的query和n个量化后的向量点乘，引入m个大小为k的量化codebook，mn可以忽略不计，k远小于n。</li>
<li>memory bandwidth：现代处理器需要“高计算量per memory read”才能充分发挥硬件的计算性能。量化压缩数据点后内存带宽的使用也下降了，变得更计算密集。</li>
<li>向量量化中引入的低bit表示，尤其是4bit量化，和低bit浮点数量化一样，可以享受SIMD、AMX的性能红利。</li>
</ul>
<h1 id="最佳实践根据应用场景将各种正交技术进行正确组合">最佳实践：根据应用场景将各种正交技术进行正确组合<a href="#最佳实践根据应用场景将各种正交技术进行正确组合" class="hanchor" ariaLabel="Anchor">&#8983;</a> </h1>
<p>HNSW、IVF、PQ、各向异性的score-aware quantization loss、brute-force事实上都是正交的技术，可以组合起来使用。</p>
<p>比如进行了PQ量化的数据点可以再构建一个HNSW，用图方法在超大规模数据集上做查询显然比ivfpq更高效。各向异性量化则是对此前PQ量化的修正。考虑到量化后的距离失真，还能用brute-force把ivf+pq+hnsw的粗排结果重算一下得到最精确的距离，由于已经经过一轮粗排，候选数据集大小从十亿级别缩小到万级别，brute-force的开销就完全可以接受了。</p>

      </div></div>

  
  
<div class="pagination">
    <div class="pagination__title">
        <span class="pagination__title-h">阅读其他博文</span>
        <hr />
    </div>
    <div class="pagination__buttons">
        
        <span class="button previous">
            <a href="https://cmbbq.github.io/posts/local-llm/">
                <span class="button__icon">←</span>
                <span class="button__text">Local LLM</span>
            </a>
        </span>
        
        
        <span class="button next">
            <a href="https://cmbbq.github.io/posts/tech-talk-evolution-of-data-center-applications/">
                <span class="button__text">Tech Talk: Evolution of Data Center Applications</span>
                <span class="button__icon">→</span>
            </a>
        </span>
        
    </div>
</div>

  

  
  

  
</div>

  </div>

  
    <footer class="footer">
  <div class="footer__inner">
    
      <div class="copyright">
        
    

        <span> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-envelope" viewBox="0 0 16 16">
          <path d="M0 4a2 2 0 0 1 2-2h12a2 2 0 0 1 2 2v8a2 2 0 0 1-2 2H2a2 2 0 0 1-2-2V4Zm2-1a1 1 0 0 0-1 1v.217l7 4.2 7-4.2V4a1 1 0 0 0-1-1H2Zm13 2.383-4.708 2.825L15 11.105V5.383Zm-.034 6.876-5.64-3.471L8 9.583l-1.326-.795-5.64 3.47A1 1 0 0 0 2 13h12a1 1 0 0 0 .966-.741ZM1 11.105l4.708-2.897L1 5.383v5.722Z"/>
        </svg> rpb.cmbbq@gmail.com </span>
      </div>
  </div>
</footer>

<script src="https://cmbbq.github.io/assets/main.js"></script>
<script src="https://cmbbq.github.io/assets/prism.js"></script>







  
</div>

</body>
</html>
