+++
title = "Digital Representations of Sound"
date = "2021-03-02"
tags = ["ai"]
description = "声音的数字表示"
showFullContent = false
+++

声音的本质是振动。

对于人耳来说，空气分子的振动抵达鼓膜时就会引起鼓膜振动——鼓膜顾名思义就是一层薄膜结构，被空气分子撞击就如同击鼓——带动鼓膜后的听小骨振动，传入内耳，再引发卵圆窗振动，卵圆窗这层薄膜之后是充满液体的耳蜗管道，这些液体随着卵圆窗振动而流动，冲刷耳蜗上的毛细胞的纤毛，从而产生生物电信号，经过神经传入大脑，就形成了听觉。

对于电容式麦克风来说，当有声音时，两块金属极板就开始振动，其间的距离会产生变化，电压形成了对空气分子振幅的模拟，因此这种电压信号被称为模拟信号。只有离散的数据才能被计算机存储、计算，因此要形成数字音频，还需要声卡的模数转换电路将连续的模拟信号采样后转化为离散的数字信号。这是一个连续曲线转化成柱状图的过程，采样率决定了柱的粗细，bit depth则决定柱高度的精度。如果bit depth为N，则振幅的取值范围为2^N，音乐App里标注的16-bit, 24-bit, 32-bit就指的是bit depth，显然bit depth越高，振幅的表示越精确。比特率bit rate = sample rate * bit depth，即每秒用多少bit来表示音频数据。

![audio1](https://cmbbq.github.io/img/audio1.png)

PGC和UGC的差别主要是信噪比，毕竟录音的时候连手机都不能带，空调、电灯都可能影响波形电平稳定。UGC可以想象，直播或者念稿子，噪声的平均振幅往往还比背景音乐更大。音频从32bit到16bit是一个量化的过程，不过无论采样精度多高，都终归是对现实的一个量化，量化error引入量化噪声，所以任何数字音频都是有底噪的——白噪声在各频率上都是一样的能量，由于能量（响度）较低，被称为noise floor，表现为微弱的嘶嘶声。

音频时域数据的纵坐标为振幅，横坐标为时间，可绘制成波形图——其震动频率决定音高，平均振幅决定响度，具体波形和这种其他因素决定音色。

![wave](https://cmbbq.github.io/img/wave.jpeg)

时域与频域是对信号波的两个观察面。时域是真实世界唯一存在的域，频域则是对时域的数学构造。任何时域信号都可以表示为不同频率的正弦波信号的叠加。

常见的音频格式包括wav、mdi、mp3、mp3pro、wma、realaudio、audible、aac、ogg vorbis、ape、flac。不同的音频编码有不同的目标，在压缩（降低传输所需信道带宽）和质量（对人耳来说）之间做tradeoff。
 
各种格式的数字音频都能转成采样率8000Hz的PCM格式音频，PCM(pulse code modulation)是最简单的时域编码方式，就是对信号的离散和量化（通常是对数量化）。1/8000s长度的帧即构成了PCM音频在时域上的最小单位，每个帧包含channel数目个采样点，如果channel数目为1，则帧大小就等于bit depth。我们可以把PCM音频切分成多个chunk，每个chunk有固定大小（比如包含1024个帧），chunk与chunk之间必须有重合（比如256个帧）。之所以要有些重合，是为了对抗Time Skew（假如不做重合，查询音频的chunk的起始帧和库中的音频各个chunk的起始帧有一定offset就查询不到了）。

![ts](https://cmbbq.github.io/img/timeskew.png)

接下来只需对各个chunk进行1维离散傅立叶变换（fftw_plan_dft_1d）就能得到各个chunk的频域信息（如下图，横坐标为频率，纵坐标为能量）。

![sp](https://cmbbq.github.io/img/spec.png)

再将这些帧的频谱按时间顺序拼起来（可以有一些重合）就形成一个y轴为频率，x轴为时间，z轴为能量的三维表面（也可以用平面彩图表示，z轴的高度换成色彩来表示能量），这就形成了频谱图（spectrogram）。

![sp](https://cmbbq.github.io/img/spec2.png)
![sp](https://cmbbq.github.io/img/spec3.png)

有了频谱图，就可以尝试从较长的数据中提炼出简短的信息作为这段音频的指纹了。在频谱图上可以逐帧找到各帧上显著的高能频率点（salient peaks，能量超过一定阈值，且比周围所有点都高）——这些点本身已经可以作为音频的指纹特征了，只是不够鲁棒，因为点与点之间是无关的，满屏都是噪点的情况下就会有误匹配。一个改进方案是这些点右侧划定一个目标区域，在区域内找出一些点，形成几个pair，这些pair叫做landmark特征，即[t1, f1, t2, f2]，其抗噪能力增强了很多。

![sp](https://cmbbq.github.io/img/spec4.png)
