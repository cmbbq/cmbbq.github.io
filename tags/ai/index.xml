<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>ai on Cmbbq&#39;s Encyclopedia</title>
    <link>https://cmbbq.github.io/tags/ai/</link>
    <description>Recent content in ai on Cmbbq&#39;s Encyclopedia</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 28 Jun 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://cmbbq.github.io/tags/ai/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Our Rationality can be Divided into Induction &amp; Deduction</title>
      <link>https://cmbbq.github.io/posts/induction-deduction/</link>
      <pubDate>Wed, 28 Jun 2023 00:00:00 +0000</pubDate>
      
      <guid>https://cmbbq.github.io/posts/induction-deduction/</guid>
      <description>诺姆·乔姆斯基说：人的无知，可分为神秘和问题(mysteries &amp;amp; problems)。
诚哉斯言，为了对抗无知，人的理性，也可分为归纳和演绎(induction &amp;amp; deduction)。
前者推断神秘，后者解决问题。
前者完备而不可计算，后者可计算而不完备。
何为问题？ 何为问题？本文中指代可求解问题——有良好定义的输入、输出，存在确定性算法能逐步计算，最终得到正确结果，比如八皇后问题，哈密顿路径问题。
何为神秘？ 何为神秘？本文中指代不可求解问题——或需要无限计算资源，或具有不可判定性质（不可判定本质上就是不可计算），比如图灵提出的不可判定的停机问题。哥德尔构造的『真但不可证』的哥德尔语句。又如纯粹贝叶斯主义的置信度计算和预测必须同时考虑无限个预测性理论，现实计算机不仅处理不了计算量的无限性，还处理不了各个算法分支的不可终止性——并不是所有计算都会终止，有的甚至越算越复杂，永不止歇。
何为演绎？ 何为演绎？本文中指代演绎推理。欧几里得几何、初等算术、图灵机、λ演算等形式化系统（或者说演绎装置），就是由一组公理和一系列推理规则所组成，允许从公理推导出新理论的系统。
数理逻辑和演绎推理具有天然的美感。我们小时候学欧式几何时，应该都赞叹过这种形式主义美感：从简洁的五条公理，竟然能推导出复杂、庞大、深邃而又确切无疑正确的体系。演绎似乎是真理之钥。
自然而然地，历史上有数学家希望将所有数学理论建立在一组有限而完备的公理基础上，提供这些公理是一致的证明。1920年代，形式主义派的领导者希尔伯特希望建立一个形式化的证明体系，用严格遵循运算规则的符号逻辑语言表述所有数学陈述，给当时正面临多种悖论危机的数学一个安全的基础。这就是希尔伯特计划，一个人类理性对抗神秘的伟大尝试。希尔伯特说：『我们必须知道，我们也终将知道！』这是形式主义者的战斗宣言，他们坚信：数学具有完备性(在形式化数学里，所有数学陈述可证)、一致性（在形式化数学里，不存在矛盾）、可判定性（总有算法能判定某个数学陈述的真假）、保守性（证明不依赖于理想对象，如不可数集合）。只要这4点假设为真，无论现实多么宏大广博，真理如何高不可攀，人类只要持有演绎推理之钥，就能证明一切真理。
然而希尔伯特计划还未开始，就被哥德尔、图灵、邱奇终结。1930年代，哥德尔提出“广义递归函数”，图灵构造“图灵机”，邱奇提出“λ演算”，三人各自独立地形式化了可计算性：λ可计算性等价于图灵机可计算性，图灵机可计算性又等价于广义递归性。哥德尔不完备定理，证明了(1)一个蕴含初等算术的形式系统，若一致，则不完备。(2)该系统的一致性不能在系统内部证明。图灵提出停机问题，证明了我们无法判定图灵机是否会停止。停机问题的不可判定性蕴含了数学的不可判定性。一旦停机问题可判定，图灵机就能用来证明任意数学问题，因为理论上我们可以编写一个图灵机程序从公理开始构造出所有定理，每个定理生成后检查一下是不是目标问题——比如孪生素数猜想——如果是，图灵机程序终止，如果不是，则不停机。
何为归纳？ 何为归纳？本文中指代统计推断，泛指是使用数据分析来推断概率分布属性的过程。
统计学有贝叶斯学派和频率学派之争。贝叶斯学派认为待估计的模型参数是一个具有模型主观性的随机变量，而用来估计模型参数的数据反过来是确定的常数，讨论观测数据的概率分布才是没有意义的，概率被解释为模型在现有知识基础上对一件事情发生的相信程度。频率学派认为事件本身具有某种客观的随机性，概率是一个确定的值，讨论概率的分布没有意义，概率只是重复实验次数趋近于无穷后频率的极限值。贝叶斯理论最早起源于1763年，此后被频率学派以居高临下的姿态视作已经足够好的正统方法的补充，或者干脆是当成某种有趣但错误的尝试。直到上个世纪末才重新被学界重视。部分原因是计算机取代计算器，成为新的计算工具，克服了贝叶斯方法在计算上的困难。在通用电子计算机出现之前，频率学派对某些特定问题做出特殊假设的做法显然更经济，往往也相当有效，只不过这些人为假设难以证伪也难以证明。
归根到底，频率学派的归纳推断只能勉强算是贝叶斯推断的近似，还有一部分近似是错误的近似。CERN通过大型强子对撞机发现希格斯玻色子，实际上就是依据：假设不存在希格斯玻色子，观测数据的p值&amp;lt;0.00003%，这个阈值看起来足够低，因此CERN的研究者以及整个人类社会就接受了希格斯玻色子的存在。这个0.0003%的阈值是哪里来的呢？和人文社科研究中那些p值&amp;lt;5%一样都来源于直觉和人为假设。所谓的科学，不过是建立在如此薄弱的基础之上。即使在物理学实验这种极端严谨的场合，基于p值的统计分析依然会造成假象。2003年的五夸克态因p值被宣布发现，然而又因原始实验无法复现而被否定。Regina Nuzzo在Nature杂志上对p值滥用进行了批判，通过实例证明科学研究中普遍存在p值统计学显著结果不可重现的问题。
1960年代，纯粹贝叶斯主义者所罗门诺夫超越了哥德尔不完备理论，超越了邱奇-图灵论题，提出了贝叶斯理论的计算形式化，即所罗门诺夫归纳推断理论，并证明了该理论具有完备性和不可计算性。所罗门诺夫给出了一个惊人的观察：完备性和可计算性，不可得兼。任何理论，只要是可计算的，就不能检出所有规律。而像所罗门诺夫归纳推断理论这样具有完备性的理论，则必然是不可计算的。
所罗门诺夫理论的完备性意味着贝叶斯公式（这里是简化表示）P(θ|d) = P(d|θ)P(θ)/P(d)几乎可以被认为是真理公式。演绎推理则是贝叶斯推理在真假确定场景下的正确特例：当P(d) = 1时，概率语言中P(θ|d) = P(d|θ)P(θ)/P(d) 就自然退化成经典逻辑语言d =&amp;gt; θ，即d蕴含θ了。
规则的尽头是贝叶斯 下图是摘自Computability and Complexity，最早出自Descriptive Complexity(Immerman 1999)的可计算性与复杂度世界图，自上而下，逐渐从神秘过渡到问题。 当我们用if else条件判断，用计算机程序语言，无论如何努力，都难以编写出效果让人满意的程序时。我们往往是在面对神秘，而非问题。
这种场景下，经典逻辑的手段已经穷尽，演绎明确不是真理之钥，但我们可以观想所罗门诺夫之妖。
所罗门诺夫之妖所喻的纯粹贝叶斯主义固然具有不可计算性，却可以被各种手段近似模拟，典型的结构就是深度神经网络，用数十亿、数百亿、数千亿个参数/权重，用臃肿笨拙地方式去模拟贝叶斯推断。
在决策和博弈型任务上，强化学习对比基于规则的方法，取得了惊人的效果。目前的强化学习基本上能求解任意人类游戏/博弈，DeepMind的星际争霸AI AlphaStar击败MaNa，Dota2的OpenAI Five击败OG，围棋的AlphaGo击败柯洁。这是此前基于规则的方法几乎不可能实现的。
在理解和生成型任务上，大语言模型对比传统的NLP方法，达到了超出训练目标的额外效果，涌现出种种惊喜，比如单步逻辑推理能力，以及某些简单复合问题的逻辑推理能力。
基于图灵机、λ演算的计算理论根基数十年岿然不动，一朝有变，则蕴含着更深刻的变革——我们正见证从图灵机的演绎推理到神经网络的统计推断的跳跃，从“可计算且不完备”到“不可计算且完备”的质变。
前文Knowledge is Embeddings of Reality中提到对音频的理解可以是不同深度，不同角度的，音乐信息检索可以用信号处理的基于规则的方法，也可以用resnet这样的深度神经网络，或whisper这样的大模型。理解愈深邃，愈不精确，应用也就愈发灵活，愈发贴近人类思维。这是理解的视角，若是从计算的视角讲，基于信号处理的系统是在做演绎推理，因此可计算性最强，但天然具有不完备性，无论我们给代码里增加多少个公理，增加多少执行路径，设计多么巧妙的手工特征，注入多么鬼斧神工的专家洞察，都总有覆盖不到的场景，甚至可以说只能覆盖到很小很小的一部分，因为音频数据来自于现实，原始数据具备极高的整体复杂度和细微结构精致度，超越了人类思考和编程的能力极限，人类专家设计的音频特征能考虑抗噪，具备简单的鲁棒性，就已经是sota了。而基于深度模型、乃至大模型的方法则是对贝叶斯推断的近似，放弃精确性、增加计算成本的同时，从演绎转变成了归纳，从收敛走向开放，哪怕仅仅是对贝叶斯的近似，也换取了一定程度上的完备性——不局限于简单的抗噪、抗变调，开始在旋律、情绪、风格，甚至歌词的语言逻辑层面上考虑音频的相似度。
认知计算：人性化与完备化的革命 基于推理的算法，本质是为形式化系统（λ演算、图灵机）手工编写公理（先验数据，如魔数、掩码表、配置文件）或规则（传统的条件控制与算术计算）进行正确、高效但不完备的演绎推理。
基于推断的算法，本质是使用形式化系统（计算神经网络依然是形式化系统，其公理变成了更庞大的模型权重，规则变成了矩阵乘加、归一化、激活函数等数学算子的组合）对所罗门诺夫归纳推断理论（形式化的纯粹贝叶斯主义）进行拙劣、错误，但有用的近似。
统计推断，模型推理，英文中都是inference，中文用词却不一，不知是巧合还是集体无意识暗合真理：推断是归纳，推理则是演绎。纯粹贝叶斯主义的所罗门诺夫归纳推断近乎全知，不可计算，无穷尽，不停机，而我们用模型权重为公理，用矩阵乘加、批正态化、激活函数组合为规则写出来的模型推理程序本质上还是基于演绎推理，训练或者说优化、学习的过程亦然。因此在计算机科学的AI应用语境下我们把inference称为推理完全合理，正如在统计学语境下我们把inference称为推断，也是无比合理的。
所谓认知计算，就是用演绎推理的凡俗躯壳容纳纯粹贝叶斯主义全知魂灵的神降，补齐符号逻辑、规则系统和信号处理手段在“人性化(align to humanity)”、“完备化(pin down reality)”上的缺憾。
可以断言，尽管AI学界和业界浮躁且浮夸，受传统学科乃至计算系统传统领域的研究者诟病，但深度学习本身绝非niche应用，更非Metaverse、Web3那种VC追逐的玩具和噱头。所有计算领域——互联网服务、数据中心应用、智能终端、游戏AI，都将受益于认知计算进步，人类文明很有可能也会进入新的阶段。
近未来人类文明在基础物理、材料、能源领域或难有寸进，但在认知科学上构筑出辉煌的认知计算体系几乎是确定性的，因为认知计算所需的硬件进步不构成瓶颈，至少不会像对撞机、深空旅行、可控核聚变那样受到时空尺度和材料极限的约束。毕竟考虑即使是小小一只蜜蜂不足2立方厘米的大脑，就能拥有超越人类目前基于规则和导航辅助的先进算法的复杂3D环境寻路避障能力和天生的贝叶斯推断能力，亿万年生物演化的自然结构已经存在，我们不必担心这种结构根本不存在：它就在那，我们所需做的仅仅是近似和模仿。</description>
      <content>&lt;p&gt;诺姆·乔姆斯基说：人的无知，可分为神秘和问题(mysteries &amp;amp; problems)。&lt;/p&gt;
&lt;p&gt;诚哉斯言，为了对抗无知，人的理性，也可分为归纳和演绎(induction &amp;amp; deduction)。&lt;/p&gt;
&lt;p&gt;前者推断神秘，后者解决问题。&lt;/p&gt;
&lt;p&gt;前者&lt;a href=&#34;(https://en.wikipedia.org/wiki/Complete_theory)&#34;&gt;完备&lt;/a&gt;而不可计算，后者&lt;a href=&#34;https://en.wikipedia.org/wiki/Computability_theory&#34;&gt;可计算&lt;/a&gt;而不完备。&lt;/p&gt;
&lt;h2 id=&#34;何为问题&#34;&gt;何为问题？&lt;/h2&gt;
&lt;p&gt;何为问题？本文中指代可求解问题——有良好定义的输入、输出，存在确定性算法能逐步计算，最终得到正确结果，比如&lt;a href=&#34;https://en.wikipedia.org/wiki/Eight_queens_puzzle&#34;&gt;八皇后问题&lt;/a&gt;，&lt;a href=&#34;https://en.wikipedia.org/wiki/Hamiltonian_path_problem&#34;&gt;哈密顿路径问题&lt;/a&gt;。&lt;/p&gt;
&lt;h2 id=&#34;何为神秘&#34;&gt;何为神秘？&lt;/h2&gt;
&lt;p&gt;何为神秘？本文中指代不可求解问题——或需要无限计算资源，或具有不可判定性质（不可判定本质上就是不可计算），比如图灵提出的&lt;a href=&#34;https://en.wikipedia.org/wiki/Undecidable_problem&#34;&gt;不可判定&lt;/a&gt;的&lt;a href=&#34;https://en.wikipedia.org/wiki/Halting_problem&#34;&gt;停机问题&lt;/a&gt;。哥德尔构造的『真但不可证』的&lt;a href=&#34;https://en.wikipedia.org/wiki/G%C3%B6del%27s_incompleteness_theorems&#34;&gt;哥德尔语句&lt;/a&gt;。又如纯粹贝叶斯主义的置信度计算和预测必须同时考虑无限个预测性理论，现实计算机不仅处理不了计算量的无限性，还处理不了各个算法分支的不可终止性——并不是所有计算都会终止，有的甚至越算越复杂，永不止歇。&lt;/p&gt;
&lt;h2 id=&#34;何为演绎&#34;&gt;何为演绎？&lt;/h2&gt;
&lt;p&gt;何为演绎？本文中指代&lt;a href=&#34;https://en.wikipedia.org/wiki/Deductive_reasoning&#34;&gt;演绎推理&lt;/a&gt;。欧几里得几何、初等算术、图灵机、&lt;a href=&#34;https://en.wikipedia.org/wiki/Lambda_calculus&#34;&gt;λ演算&lt;/a&gt;等形式化系统（或者说演绎装置），就是由一组公理和一系列推理规则所组成，允许从公理推导出新理论的系统。&lt;/p&gt;
&lt;p&gt;数理逻辑和演绎推理具有天然的美感。我们小时候学欧式几何时，应该都赞叹过这种形式主义美感：从简洁的五条公理，竟然能推导出复杂、庞大、深邃而又确切无疑正确的体系。演绎似乎是真理之钥。&lt;/p&gt;
&lt;p&gt;自然而然地，历史上有数学家希望将所有数学理论建立在一组有限而完备的公理基础上，提供这些公理是一致的证明。1920年代，形式主义派的领导者希尔伯特希望建立一个形式化的证明体系，用严格遵循运算规则的符号逻辑语言表述所有数学陈述，给当时正面临多种&lt;a href=&#34;https://en.wikipedia.org/wiki/Foundations_of_mathematics#Foundational_crisis&#34;&gt;悖论危机&lt;/a&gt;的数学一个安全的基础。这就是&lt;a href=&#34;https://en.wikipedia.org/wiki/Hilbert%27s_program&#34;&gt;希尔伯特计划&lt;/a&gt;，一个人类理性对抗神秘的伟大尝试。希尔伯特说：『我们必须知道，我们也终将知道！』这是形式主义者的战斗宣言，他们坚信：数学具有完备性(在形式化数学里，所有数学陈述可证)、一致性（在形式化数学里，不存在矛盾）、可判定性（总有算法能判定某个数学陈述的真假）、保守性（证明不依赖于理想对象，如不可数集合）。只要这4点假设为真，无论现实多么宏大广博，真理如何高不可攀，人类只要持有演绎推理之钥，就能证明一切真理。&lt;/p&gt;
&lt;p&gt;然而希尔伯特计划还未开始，就被哥德尔、图灵、邱奇终结。1930年代，哥德尔提出“广义递归函数”，图灵构造“图灵机”，邱奇提出“λ演算”，三人各自独立地形式化了可计算性：λ可计算性等价于图灵机可计算性，图灵机可计算性又等价于广义递归性。&lt;a href=&#34;https://en.wikipedia.org/wiki/G%C3%B6del%27s_incompleteness_theorems#First_incompleteness_theorem&#34;&gt;哥德尔不完备定理&lt;/a&gt;，证明了(1)一个蕴含初等算术的形式系统，若一致，则不完备。(2)该系统的一致性不能在系统内部证明。图灵提出停机问题，证明了我们无法判定图灵机是否会停止。停机问题的不可判定性蕴含了数学的不可判定性。一旦停机问题可判定，图灵机就能用来证明任意数学问题，因为理论上我们可以编写一个图灵机程序从公理开始构造出所有定理，每个定理生成后检查一下是不是目标问题——比如孪生素数猜想——如果是，图灵机程序终止，如果不是，则不停机。&lt;/p&gt;
&lt;h2 id=&#34;何为归纳&#34;&gt;何为归纳？&lt;/h2&gt;
&lt;p&gt;何为归纳？本文中指代&lt;a href=&#34;https://en.wikipedia.org/wiki/Statistical_inference&#34;&gt;统计推断&lt;/a&gt;，泛指是使用数据分析来推断概率分布属性的过程。&lt;/p&gt;
&lt;p&gt;统计学有贝叶斯学派和频率学派之争。贝叶斯学派认为待估计的模型参数是一个具有模型主观性的随机变量，而用来估计模型参数的数据反过来是确定的常数，讨论观测数据的概率分布才是没有意义的，概率被解释为模型在现有知识基础上对一件事情发生的相信程度。频率学派认为事件本身具有某种客观的随机性，概率是一个确定的值，讨论概率的分布没有意义，概率只是重复实验次数趋近于无穷后频率的极限值。贝叶斯理论最早起源于1763年，此后被频率学派以居高临下的姿态视作已经足够好的正统方法的补充，或者干脆是当成某种有趣但错误的尝试。直到上个世纪末才重新被学界重视。部分原因是计算机取代计算器，成为新的计算工具，克服了贝叶斯方法在计算上的困难。在通用电子计算机出现之前，频率学派对某些特定问题做出特殊假设的做法显然更经济，往往也相当有效，只不过这些人为假设难以证伪也难以证明。&lt;/p&gt;
&lt;p&gt;归根到底，频率学派的归纳推断只能勉强算是贝叶斯推断的近似，还有一部分近似是错误的近似。CERN通过大型强子对撞机发现希格斯玻色子，实际上就是依据：假设不存在希格斯玻色子，观测数据的p值&amp;lt;0.00003%，这个阈值看起来足够低，因此CERN的研究者以及整个人类社会就接受了希格斯玻色子的存在。这个0.0003%的阈值是哪里来的呢？和人文社科研究中那些p值&amp;lt;5%一样都来源于直觉和人为假设。所谓的科学，不过是建立在如此薄弱的基础之上。即使在物理学实验这种极端严谨的场合，基于p值的统计分析依然会造成假象。2003年的五夸克态因p值被宣布发现，然而又因原始实验无法复现而被否定。&lt;a href=&#34;https://www.nature.com/articles/506150a&#34;&gt;Regina Nuzzo在Nature杂志上对p值滥用进行了批判&lt;/a&gt;，通过实例证明科学研究中普遍存在p值统计学显著结果不可重现的问题。&lt;/p&gt;
&lt;p&gt;1960年代，纯粹贝叶斯主义者所罗门诺夫超越了哥德尔不完备理论，超越了邱奇-图灵论题，提出了贝叶斯理论的计算形式化，即&lt;a href=&#34;https://en.wikipedia.org/wiki/Solomonoff%27s_theory_of_inductive_inference&#34;&gt;所罗门诺夫归纳推断理论&lt;/a&gt;，并证明了该理论具有完备性和不可计算性。所罗门诺夫给出了一个惊人的观察：完备性和可计算性，不可得兼。任何理论，只要是可计算的，就不能检出所有规律。而像所罗门诺夫归纳推断理论这样具有完备性的理论，则必然是不可计算的。&lt;/p&gt;
&lt;p&gt;所罗门诺夫理论的完备性意味着贝叶斯公式（这里是简化表示）P(θ|d) = P(d|θ)P(θ)/P(d)几乎可以被认为是真理公式。演绎推理则是贝叶斯推理在真假确定场景下的正确特例：当P(d) = 1时，概率语言中P(θ|d) = P(d|θ)P(θ)/P(d) 就自然退化成经典逻辑语言d =&amp;gt; θ，即d蕴含θ了。&lt;/p&gt;
&lt;h2 id=&#34;规则的尽头是贝叶斯&#34;&gt;规则的尽头是贝叶斯&lt;/h2&gt;
&lt;p&gt;下图是摘自&lt;a href=&#34;https://plato.stanford.edu/entries/computability&#34;&gt;Computability and Complexity&lt;/a&gt;，最早出自Descriptive Complexity(Immerman 1999)的可计算性与复杂度世界图，自上而下，逐渐从神秘过渡到问题。
&lt;img src=&#34;https://cmbbq.github.io/img/CaC.jpeg&#34; alt=&#34;cac&#34;&gt;&lt;/p&gt;
&lt;p&gt;当我们用if else条件判断，用计算机程序语言，无论如何努力，都难以编写出效果让人满意的程序时。我们往往是在面对神秘，而非问题。&lt;/p&gt;
&lt;p&gt;这种场景下，经典逻辑的手段已经穷尽，演绎明确不是真理之钥，但我们可以观想所罗门诺夫之妖。&lt;/p&gt;
&lt;p&gt;所罗门诺夫之妖所喻的纯粹贝叶斯主义固然具有不可计算性，却可以被各种手段近似模拟，典型的结构就是深度神经网络，用数十亿、数百亿、数千亿个参数/权重，用臃肿笨拙地方式去模拟贝叶斯推断。&lt;/p&gt;
&lt;p&gt;在决策和博弈型任务上，强化学习对比基于规则的方法，取得了惊人的效果。目前的强化学习基本上能求解任意人类游戏/博弈，DeepMind的星际争霸AI AlphaStar击败MaNa，Dota2的OpenAI Five击败OG，围棋的AlphaGo击败柯洁。这是此前基于规则的方法几乎不可能实现的。&lt;/p&gt;
&lt;p&gt;在理解和生成型任务上，大语言模型对比传统的NLP方法，达到了超出训练目标的额外效果，涌现出种种惊喜，比如单步逻辑推理能力，以及某些简单复合问题的逻辑推理能力。&lt;/p&gt;
&lt;p&gt;基于图灵机、λ演算的计算理论根基数十年岿然不动，一朝有变，则蕴含着更深刻的变革——我们正见证从图灵机的演绎推理到神经网络的统计推断的跳跃，从“可计算且不完备”到“不可计算且完备”的质变。&lt;/p&gt;
&lt;p&gt;前文&lt;a href=&#34;https://cmbbq.github.io/posts/reality-knowledge&#34;&gt;Knowledge is Embeddings of Reality&lt;/a&gt;中提到对音频的理解可以是不同深度，不同角度的，音乐信息检索可以用信号处理的基于规则的方法，也可以用resnet这样的深度神经网络，或whisper这样的大模型。理解愈深邃，愈不精确，应用也就愈发灵活，愈发贴近人类思维。这是理解的视角，若是从计算的视角讲，基于信号处理的系统是在做演绎推理，因此可计算性最强，但天然具有不完备性，无论我们给代码里增加多少个公理，增加多少执行路径，设计多么巧妙的手工特征，注入多么鬼斧神工的专家洞察，都总有覆盖不到的场景，甚至可以说只能覆盖到很小很小的一部分，因为音频数据来自于现实，原始数据具备极高的整体复杂度和细微结构精致度，超越了人类思考和编程的能力极限，人类专家设计的音频特征能考虑抗噪，具备简单的鲁棒性，就已经是sota了。而基于深度模型、乃至大模型的方法则是对贝叶斯推断的近似，放弃精确性、增加计算成本的同时，从演绎转变成了归纳，从收敛走向开放，哪怕仅仅是对贝叶斯的近似，也换取了一定程度上的完备性——不局限于简单的抗噪、抗变调，开始在旋律、情绪、风格，甚至歌词的语言逻辑层面上考虑音频的相似度。&lt;/p&gt;
&lt;h2 id=&#34;认知计算人性化与完备化的革命&#34;&gt;认知计算：人性化与完备化的革命&lt;/h2&gt;
&lt;p&gt;基于推理的算法，本质是为形式化系统（λ演算、图灵机）手工编写公理（先验数据，如魔数、掩码表、配置文件）或规则（传统的条件控制与算术计算）进行正确、高效但不完备的演绎推理。&lt;/p&gt;
&lt;p&gt;基于推断的算法，本质是使用形式化系统（计算神经网络依然是形式化系统，其公理变成了更庞大的模型权重，规则变成了矩阵乘加、归一化、激活函数等数学算子的组合）对&lt;a href=&#34;https://en.wikipedia.org/wiki/Solomonoff%27s_theory_of_inductive_inference&#34;&gt;所罗门诺夫归纳推断理论&lt;/a&gt;（形式化的纯粹贝叶斯主义）进行拙劣、错误，但有用的近似。&lt;/p&gt;
&lt;p&gt;统计推断，模型推理，英文中都是inference，中文用词却不一，不知是巧合还是集体无意识暗合真理：推断是归纳，推理则是演绎。纯粹贝叶斯主义的所罗门诺夫归纳推断近乎全知，不可计算，无穷尽，不停机，而我们用模型权重为公理，用矩阵乘加、批正态化、激活函数组合为规则写出来的模型推理程序本质上还是基于演绎推理，训练或者说优化、学习的过程亦然。因此在计算机科学的AI应用语境下我们把inference称为推理完全合理，正如在统计学语境下我们把inference称为推断，也是无比合理的。&lt;/p&gt;
&lt;p&gt;所谓认知计算，就是用演绎推理的凡俗躯壳容纳纯粹贝叶斯主义全知魂灵的神降，补齐符号逻辑、规则系统和信号处理手段在“人性化(align to humanity)”、“完备化(pin down reality)”上的缺憾。&lt;/p&gt;
&lt;p&gt;可以断言，尽管AI学界和业界浮躁且浮夸，受传统学科乃至计算系统传统领域的研究者诟病，但深度学习本身绝非niche应用，更非Metaverse、Web3那种VC追逐的玩具和噱头。所有计算领域——互联网服务、数据中心应用、智能终端、游戏AI，都将受益于认知计算进步，人类文明很有可能也会进入新的阶段。&lt;/p&gt;
&lt;p&gt;近未来人类文明在基础物理、材料、能源领域或难有寸进，但在认知科学上构筑出辉煌的认知计算体系几乎是确定性的，因为认知计算所需的硬件进步不构成瓶颈，至少不会像对撞机、深空旅行、可控核聚变那样受到时空尺度和材料极限的约束。毕竟考虑即使是小小一只蜜蜂不足2立方厘米的大脑，就能拥有超越人类目前基于规则和导航辅助的先进算法的复杂3D环境寻路避障能力和天生的贝叶斯推断能力，亿万年生物演化的自然结构已经存在，我们不必担心这种结构根本不存在：它就在那，我们所需做的仅仅是近似和模仿。&lt;/p&gt;
</content>
    </item>
    
    <item>
      <title>Knowledge is Embeddings of Reality</title>
      <link>https://cmbbq.github.io/posts/reality-knowledge/</link>
      <pubDate>Wed, 07 Jun 2023 00:00:00 +0000</pubDate>
      
      <guid>https://cmbbq.github.io/posts/reality-knowledge/</guid>
      <description>现实有无限维度，现实的背后还有潜在现实，结构的边缘会涌现出新的深层结构。
人类对现实的感知、认知、理解，本质上是将高维现实投射到一个低维表示上，这种低维表示在统计学和机器学习中被称为embedding（嵌入），没错，知识就是将现实在人类有限的认知空间的一个嵌入，紧凑、浅薄且片面。
举个具体的例子，人眼观察到的彩虹呈现七色。
但这只是对无限广博的现实的最初观察，是最直观的认知。
人类通过对人体生理学的研究，发现七色感知是一个更深层的潜在现实的涌现结构：多种光感受器的叠加反应。
人类颜色感知系统对红绿蓝敏感的三种光感受器，叠加反应产生的三个峰和四个谷决定了人类能感知到7种颜色。 鸟类由于拥有对紫外线敏感的光感受器，就能感知到9种颜色，因此可以看到九色彩虹。
无论人类的七色彩虹还是鸟类的九色彩虹，都只是知识（或者说embedding），而不是现实。
人类通过数学工具和电磁学研究，进一步认识到光谱是连续的，包括无线电波、微波、热、红外线、可见光、紫外线等。
这接近现实了吗？不，这依然只是浅薄的embedding。。
人类通过量子物理学的研究，发现现有的电磁学依旧是一个更深层的潜在现实的涌现模型——电磁波是量子粒子流的一种表现形式：光子。
光子的认知，折射出更复杂的现实，因为一个光子同时拥有无限的位置和频率，直到被观察到才能确定其位置或能量，需用海森堡不确定性原理、薛定谔方程来描述，这依旧不是真理，不是终极，仍然是在现实之上所施加的结构(structure imposed upon reality)。
类似地，现实中的一首歌曲，看似简单平凡，实际上却拥有无穷维度，我们可以从任意一个角度去理解它，将它嵌入到任意一个向量空间。
假设用户手机的传感器捕捉了一段音频，将其上传到平台上，消重（时频图的mask特征）、指纹(时频图的landmark特征)、翻唱（浅层cnn）、哼唱（whisper大模型）、多模态大模型应用分别捕捉了这段音频的某种特征，产生了不同层次的知识（embedding），理解愈发深邃，愈发不精确，应用也就愈发灵活，愈发贴近人类思维。
后端的消重服务或指纹服务将表示音频的信号采样数据通过fft计算得到时频图，再基于时频图提取某种mask特征或landmark特征，用于直接刻画其能量分布特征，然后与音频特征库里存着的现有特征做对比就可以找到匹配的音频，这就是音频消重和指纹识别的过程：对信号做简单数学处理，生成的就是高度特化、具体、紧凑、确定、可解释的知识，表示这种知识的embedding或不具有抗噪性（mask特征），或具有少许抗噪性（landmark特征），但无论如何都只适用于原曲匹配，不知何为翻唱，何为remix，何为二创，何为串烧。
翻唱识别服务能通过一个学习了歌曲旋律的神经网络对音频信号进行处理，产出一定程度上表达旋律特征的embedding，将曲库里的翻唱embedding存入向量数据库，通过KNN/ANN召回的结果往往不限于原曲，还能容忍变调、音色上的改变。
哼唱识别服务可以基于Whisper这样的音频大模型实现，这种深层网络学习了人类的自然语言，因此对音频信号处理时，提取了表达歌词信息的embedding。基于这样的embedding，可以在跑调非常严重，且没有伴奏的情况下，依然能识别出用户在哼什么歌。
考虑未来的多模态大模型，更是可以直接将embedding存在transformer的ffn层，不必借助外部的向量数据库或倒排索引，直接在模型内部刻画embedding之间的复杂关系，让更多概念之间产生关联：识别出歌曲的意境、歌唱者的情绪、歌词内容的图片，甚至联系用户交互的上下文，衍生出更客制化、场景相关的输出。
人工智能领域用transformer简单搭建的大模型拥有出人意料的逻辑能力，昭示着人类意识的本质或许原本就极端肤浅：将知识内化、知识关联后，用天生的脑回路做贝叶斯推理，就产生了逻辑，诚然现有的结构远不如人脑高效，但有和无的界限已经被突破。
足够好的计算神经网络可以被视作神经科学的涌现模型。 一如往昔。 一如神经科学是细胞生物学的涌现。 一如细胞生物学是分子生物学的涌现。 一如分子生物学是物理化学的涌现。 一如物理化学是量子物理的涌现。</description>
      <content>&lt;p&gt;现实有无限维度，现实的背后还有潜在现实，结构的边缘会涌现出新的深层结构。&lt;/p&gt;
&lt;p&gt;人类对现实的感知、认知、理解，本质上是将高维现实投射到一个低维表示上，这种低维表示在统计学和机器学习中被称为embedding（嵌入），没错，知识就是将现实在人类有限的认知空间的一个嵌入，紧凑、浅薄且片面。&lt;/p&gt;
&lt;p&gt;举个具体的例子，人眼观察到的彩虹呈现七色。&lt;/p&gt;
&lt;p&gt;但这只是对无限广博的现实的最初观察，是最直观的认知。&lt;/p&gt;
&lt;p&gt;人类通过对人体生理学的研究，发现七色感知是一个更深层的潜在现实的涌现结构：多种光感受器的叠加反应。&lt;/p&gt;
&lt;p&gt;人类颜色感知系统对红绿蓝敏感的三种光感受器，叠加反应产生的三个峰和四个谷决定了人类能感知到7种颜色。
&lt;img src=&#34;https://cmbbq.github.io/img/color.png&#34; alt=&#34;color&#34;&gt;&lt;/p&gt;
&lt;p&gt;鸟类由于拥有对紫外线敏感的光感受器，就能感知到9种颜色，因此可以看到九色彩虹。&lt;/p&gt;
&lt;p&gt;无论人类的七色彩虹还是鸟类的九色彩虹，都只是知识（或者说embedding），而不是现实。&lt;/p&gt;
&lt;p&gt;人类通过数学工具和电磁学研究，进一步认识到光谱是连续的，包括无线电波、微波、热、红外线、可见光、紫外线等。&lt;/p&gt;
&lt;p&gt;这接近现实了吗？不，这依然只是浅薄的embedding。。&lt;/p&gt;
&lt;p&gt;人类通过量子物理学的研究，发现现有的电磁学依旧是一个更深层的潜在现实的涌现模型——电磁波是量子粒子流的一种表现形式：光子。&lt;/p&gt;
&lt;p&gt;光子的认知，折射出更复杂的现实，因为一个光子同时拥有无限的位置和频率，直到被观察到才能确定其位置或能量，需用海森堡不确定性原理、薛定谔方程来描述，这依旧不是真理，不是终极，仍然是在现实之上所施加的结构(structure imposed upon reality)。&lt;/p&gt;
&lt;p&gt;类似地，现实中的一首歌曲，看似简单平凡，实际上却拥有无穷维度，我们可以从任意一个角度去理解它，将它嵌入到任意一个向量空间。&lt;/p&gt;
&lt;p&gt;假设用户手机的传感器捕捉了一段音频，将其上传到平台上，消重（时频图的mask特征）、指纹(时频图的landmark特征)、翻唱（浅层cnn）、哼唱（whisper大模型）、多模态大模型应用分别捕捉了这段音频的某种特征，产生了不同层次的知识（embedding），理解愈发深邃，愈发不精确，应用也就愈发灵活，愈发贴近人类思维。&lt;/p&gt;
&lt;p&gt;后端的消重服务或指纹服务将表示音频的信号采样数据通过fft计算得到时频图，再基于时频图提取某种mask特征或landmark特征，用于直接刻画其能量分布特征，然后与音频特征库里存着的现有特征做对比就可以找到匹配的音频，这就是音频消重和指纹识别的过程：对信号做简单数学处理，生成的就是高度特化、具体、紧凑、确定、可解释的知识，表示这种知识的embedding或不具有抗噪性（mask特征），或具有少许抗噪性（landmark特征），但无论如何都只适用于原曲匹配，不知何为翻唱，何为remix，何为二创，何为串烧。&lt;/p&gt;
&lt;p&gt;翻唱识别服务能通过一个学习了歌曲旋律的神经网络对音频信号进行处理，产出一定程度上表达旋律特征的embedding，将曲库里的翻唱embedding存入向量数据库，通过KNN/ANN召回的结果往往不限于原曲，还能容忍变调、音色上的改变。&lt;/p&gt;
&lt;p&gt;哼唱识别服务可以基于Whisper这样的音频大模型实现，这种深层网络学习了人类的自然语言，因此对音频信号处理时，提取了表达歌词信息的embedding。基于这样的embedding，可以在跑调非常严重，且没有伴奏的情况下，依然能识别出用户在哼什么歌。&lt;/p&gt;
&lt;p&gt;考虑未来的多模态大模型，更是可以直接将embedding存在transformer的ffn层，不必借助外部的向量数据库或倒排索引，直接在模型内部刻画embedding之间的复杂关系，让更多概念之间产生关联：识别出歌曲的意境、歌唱者的情绪、歌词内容的图片，甚至联系用户交互的上下文，衍生出更客制化、场景相关的输出。&lt;/p&gt;
&lt;p&gt;人工智能领域用transformer简单搭建的大模型拥有出人意料的逻辑能力，昭示着人类意识的本质或许原本就极端肤浅：将知识内化、知识关联后，用天生的脑回路做贝叶斯推理，就产生了逻辑，诚然现有的结构远不如人脑高效，但有和无的界限已经被突破。&lt;/p&gt;
&lt;p&gt;足够好的计算神经网络可以被视作神经科学的涌现模型。
一如往昔。
一如神经科学是细胞生物学的涌现。
一如细胞生物学是分子生物学的涌现。
一如分子生物学是物理化学的涌现。
一如物理化学是量子物理的涌现。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cmbbq.github.io/img/em.png&#34; alt=&#34;em&#34;&gt;&lt;/p&gt;
</content>
    </item>
    
    <item>
      <title>On NCO</title>
      <link>https://cmbbq.github.io/posts/on-nco/</link>
      <pubDate>Wed, 12 Oct 2022 00:00:00 +0000</pubDate>
      
      <guid>https://cmbbq.github.io/posts/on-nco/</guid>
      <description>凸优化收敛时间一般是polynomial的，线性规划和最小二乘就是凸优化的特例。
非凸优化non-convex optimization是一种至少np-hard的问题，不存在通用解法。想要确定问题是否有解，局部最优是否全局最优，或目标函数是否有界都会随着变量和约束数目指数爆炸blow up，局部优化手段对算法参数敏感，又高度依赖initial guess，这使局部非凸优化more-art-than-technology，相比而言线性规划是毫无art可言的。
深度神经网络作为通用函数拟合器，最重要的作用是拟合非凸函数，因为复杂问题一般不可以用凸函数拟合。ChatGPT这类生成式模型就是对target和input间互信息的非凸优化。怎么训好模型，目前依然是一个art。
随机梯度下降stochastic gradient descent(SGD)被证明可以收敛于凸函数、可微和利普希茨连续函数，但还不能确定在非凸函数上的效果，SGD收敛缓慢，还不一定达到局部最优，更不一定达到全局最优。如果选择一个足够靠近全局最优的点，或许可以用SGD收敛到全局最优，但这一方面耗时间，另一方面只适用于特殊场景。对于深度神经网络来说，一旦陷入错误的局部最优，就要用不同的初始化配置或加入额外的梯度更新噪音。如果遇到鞍点，则需找到海森矩阵或计算下降方向。如果陷入低梯度区域，则需batchnorm，或使用relu做激活函数。如果因高曲率而使得steps过大，则应使用adaptive step size或限制梯度step尺度。此外，如果超参有问题，还需要用各种超参优化的方法。总之，目前深度学习的NCO还是处于art的阶段。</description>
      <content>&lt;p&gt;凸优化收敛时间一般是polynomial的，线性规划和最小二乘就是凸优化的特例。&lt;/p&gt;
&lt;p&gt;非凸优化non-convex optimization是一种至少np-hard的问题，不存在通用解法。想要确定问题是否有解，局部最优是否全局最优，或目标函数是否有界都会随着变量和约束数目指数爆炸blow up，局部优化手段对算法参数敏感，又高度依赖initial guess，这使局部非凸优化more-art-than-technology，相比而言线性规划是毫无art可言的。&lt;/p&gt;
&lt;p&gt;深度神经网络作为通用函数拟合器，最重要的作用是拟合非凸函数，因为复杂问题一般不可以用凸函数拟合。ChatGPT这类生成式模型就是对target和input间互信息的非凸优化。怎么训好模型，目前依然是一个art。&lt;/p&gt;
&lt;p&gt;随机梯度下降stochastic gradient descent(SGD)被证明可以收敛于凸函数、可微和利普希茨连续函数，但还不能确定在非凸函数上的效果，SGD收敛缓慢，还不一定达到局部最优，更不一定达到全局最优。如果选择一个足够靠近全局最优的点，或许可以用SGD收敛到全局最优，但这一方面耗时间，另一方面只适用于特殊场景。对于深度神经网络来说，一旦陷入错误的局部最优，就要用不同的初始化配置或加入额外的梯度更新噪音。如果遇到鞍点，则需找到海森矩阵或计算下降方向。如果陷入低梯度区域，则需batchnorm，或使用relu做激活函数。如果因高曲率而使得steps过大，则应使用adaptive step size或限制梯度step尺度。此外，如果超参有问题，还需要用各种超参优化的方法。总之，目前深度学习的NCO还是处于art的阶段。&lt;/p&gt;
</content>
    </item>
    
    <item>
      <title>A Decade of Tussle between CPU and GPU</title>
      <link>https://cmbbq.github.io/posts/a-decade-of-tussle-between-cpu-and-gpu/</link>
      <pubDate>Sun, 25 Sep 2022 00:00:00 +0000</pubDate>
      
      <guid>https://cmbbq.github.io/posts/a-decade-of-tussle-between-cpu-and-gpu/</guid>
      <description>GPU和CPU方法的边界何在？ 做AI应用的架构工作，遇到新的计算密集任务的第一问往往是：这应该上GPU，还是NUMA物理机？
这个问题可以归约为On the Limits of GPU Acceleration(2010)中提出的问题：&amp;ldquo;大致相同能耗的前提下，能和不能用GPU有效加速计算的边界在哪？&amp;rdquo; Vuduc的这个研究分析了3种具有代表性复杂行为和访存不规则性的计算：稀疏线性系统的迭代求解器、稀疏矩阵的乔列斯基分解、快速多极子算法，得出的结论是——大致地说，良好优化的GPU实现在相同能耗下和良好优化的CPU实现在性能上是相仿的。可见当年用GPGPU加速还是一个普遍得不偿失的工作，毕竟要付出剧烈变更编程模型的代价。
GPU和CPU的价格-性能趋势 上述结论在2010年成立，如今13年过去了，GPU固然飞速发展（无论是硬件、软件，还是生态、应用、资金投入），但GPU发展速度是否已经甩开CPU了呢？
摩尔定律是两年翻倍，而黄氏定律则是宣称通过软硬件协同能达到1.08年翻倍。
甚至如果我们考虑成本因素，根据经验数据，GPU FLOP/s每刀的增长速度是和CPU相仿的。这和2023年工业界的经验是吻合的——CPU在大多数应用语境下依然是成本更低的选择。</description>
      <content>&lt;h2 id=&#34;gpu和cpu方法的边界何在&#34;&gt;GPU和CPU方法的边界何在？&lt;/h2&gt;
&lt;p&gt;做AI应用的架构工作，遇到新的计算密集任务的第一问往往是：这应该上GPU，还是NUMA物理机？&lt;/p&gt;
&lt;p&gt;这个问题可以归约为&lt;a href=&#34;https://www.usenix.org/legacy/event/hotpar10/tech/full_papers/main.pdf&#34;&gt;On the Limits of GPU Acceleration(2010)&lt;/a&gt;中提出的问题：&amp;ldquo;大致相同能耗的前提下，能和不能用GPU有效加速计算的边界在哪？&amp;rdquo; Vuduc的这个研究分析了3种具有代表性复杂行为和访存不规则性的计算：稀疏线性系统的迭代求解器、稀疏矩阵的乔列斯基分解、快速多极子算法，得出的结论是——大致地说，良好优化的GPU实现在相同能耗下和良好优化的CPU实现在性能上是相仿的。可见当年用GPGPU加速还是一个普遍得不偿失的工作，毕竟要付出剧烈变更编程模型的代价。&lt;/p&gt;
&lt;h2 id=&#34;gpu和cpu的价格-性能趋势&#34;&gt;GPU和CPU的价格-性能趋势&lt;/h2&gt;
&lt;p&gt;上述结论在2010年成立，如今13年过去了，GPU固然飞速发展（无论是硬件、软件，还是生态、应用、资金投入），但GPU发展速度是否已经甩开CPU了呢？&lt;/p&gt;
&lt;p&gt;摩尔定律是两年翻倍，而&lt;a href=&#34;https://en.wikipedia.org/wiki/Huang%27s_law&#34;&gt;黄氏定律&lt;/a&gt;则是宣称通过软硬件协同能达到1.08年翻倍。&lt;/p&gt;
&lt;p&gt;甚至如果我们考虑成本因素，根据&lt;a href=&#34;https://epochai.org/blog/trends-in-gpu-price-performance&#34;&gt;经验数据&lt;/a&gt;，GPU FLOP/s每刀的增长速度是和CPU相仿的。这和2023年工业界的经验是吻合的——CPU在大多数应用语境下依然是成本更低的选择。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cmbbq.github.io/img/4.png&#34; alt=&#34;Emprical GPU/CPU FLOP/s per dollar1&#34;&gt;
&lt;img src=&#34;https://cmbbq.github.io/img/5.png&#34; alt=&#34;Emprical GPU/CPU FLOP/s per dollar2&#34;&gt;
&lt;img src=&#34;https://cmbbq.github.io/img/6.png&#34; alt=&#34;Emprical GPU/CPU FLOP/s per dollar3&#34;&gt;&lt;/p&gt;
</content>
    </item>
    
    <item>
      <title>Digital Representation of Sound</title>
      <link>https://cmbbq.github.io/posts/digital-representation-of-sound/</link>
      <pubDate>Tue, 02 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://cmbbq.github.io/posts/digital-representation-of-sound/</guid>
      <description>声音的本质是振动。
对于人耳来说，空气分子的振动抵达鼓膜时就会引起鼓膜振动——鼓膜顾名思义就是一层薄膜结构，被空气分子撞击就如同击鼓——带动鼓膜后的听小骨振动，传入内耳，再引发卵圆窗振动，卵圆窗这层薄膜之后是充满液体的耳蜗管道，这些液体随着卵圆窗振动而流动，冲刷耳蜗上的毛细胞的纤毛，从而产生生物电信号，经过神经传入大脑，就形成了听觉。
对于电容式麦克风来说，当有声音时，两块金属极板就开始振动，其间的距离会产生变化，电压形成了对空气分子振幅的模拟，因此这种电压信号被称为模拟信号。只有离散的数据才能被计算机存储、计算，因此要形成数字音频，还需要声卡的模数转换电路将连续的模拟信号采样后转化为离散的数字信号。这是一个连续曲线转化成柱状图的过程，采样率决定了柱的粗细，bit depth则决定柱高度的精度。如果bit depth为N，则振幅的取值范围为2^N，音乐App里标注的16-bit, 24-bit, 32-bit就指的是bit depth，显然bit depth越高，振幅的表示越精确。比特率bit rate = sample rate * bit depth，即每秒用多少bit来表示音频数据。
PGC和UGC的差别主要是信噪比，毕竟录音的时候连手机都不能带，空调、电灯都可能影响波形电平稳定。UGC可以想象，直播或者念稿子，噪声的平均振幅往往还比背景音乐更大。音频从32bit到16bit是一个量化的过程，不过无论采样精度多高，都终归是对现实的一个量化，量化error引入量化噪声，所以任何数字音频都是有底噪的——白噪声在各频率上都是一样的能量，由于能量（响度）较低，被称为noise floor，表现为微弱的嘶嘶声。
音频时域数据的纵坐标为振幅，横坐标为时间，可绘制成波形图——其震动频率决定音高，平均振幅决定响度，具体波形和这种其他因素决定音色。
时域与频域是对信号波的两个观察面。时域是真实世界唯一存在的域，频域则是对时域的数学构造。任何时域信号都可以表示为不同频率的正弦波信号的叠加。
常见的音频格式包括wav、mdi、mp3、mp3pro、wma、realaudio、audible、aac、ogg vorbis、ape、flac。不同的音频编码有不同的目标，在压缩（降低传输所需信道带宽）和质量（对人耳来说）之间做tradeoff。
各种格式的数字音频都能转成采样率8000Hz的PCM格式音频，PCM(pulse code modulation)是最简单的时域编码方式，就是对信号的离散和量化（通常是对数量化）。1/8000s长度的帧即构成了PCM音频在时域上的最小单位，每个帧包含channel数目个采样点，如果channel数目为1，则帧大小就等于bit depth。我们可以把PCM音频切分成多个chunk，每个chunk有固定大小（比如包含1024个帧），chunk与chunk之间必须有重合（比如256个帧）。之所以要有些重合，是为了对抗Time Skew（假如不做重合，查询音频的chunk的起始帧和库中的音频各个chunk的起始帧有一定offset就查询不到了）。
接下来只需对各个chunk进行1维离散傅立叶变换（fftw_plan_dft_1d）就能得到各个chunk的频域信息（如下图，横坐标为频率，纵坐标为能量）。
再将这些帧的频谱按时间顺序拼起来（可以有一些重合）就形成一个y轴为频率，x轴为时间，z轴为能量的三维表面（也可以用平面彩图表示，z轴的高度换成色彩来表示能量），这就形成了频谱图（spectrogram）。
有了频谱图，就可以尝试从较长的数据中提炼出简短的信息作为这段音频的指纹了。在频谱图上可以逐帧找到各帧上显著的高能频率点（salient peaks，能量超过一定阈值，且比周围所有点都高）——这些点本身已经可以作为音频的指纹特征了，只是不够鲁棒，因为点与点之间是无关的，满屏都是噪点的情况下就会有误匹配。一个改进方案是这些点右侧划定一个目标区域，在区域内找出一些点，形成几个pair，这些pair叫做landmark特征，即[t1, f1, t2, f2]，其抗噪能力增强了很多。</description>
      <content>&lt;p&gt;声音的本质是振动。&lt;/p&gt;
&lt;p&gt;对于人耳来说，空气分子的振动抵达鼓膜时就会引起鼓膜振动——鼓膜顾名思义就是一层薄膜结构，被空气分子撞击就如同击鼓——带动鼓膜后的听小骨振动，传入内耳，再引发卵圆窗振动，卵圆窗这层薄膜之后是充满液体的耳蜗管道，这些液体随着卵圆窗振动而流动，冲刷耳蜗上的毛细胞的纤毛，从而产生生物电信号，经过神经传入大脑，就形成了听觉。&lt;/p&gt;
&lt;p&gt;对于电容式麦克风来说，当有声音时，两块金属极板就开始振动，其间的距离会产生变化，电压形成了对空气分子振幅的模拟，因此这种电压信号被称为模拟信号。只有离散的数据才能被计算机存储、计算，因此要形成数字音频，还需要声卡的模数转换电路将连续的模拟信号采样后转化为离散的数字信号。这是一个连续曲线转化成柱状图的过程，采样率决定了柱的粗细，bit depth则决定柱高度的精度。如果bit depth为N，则振幅的取值范围为2^N，音乐App里标注的16-bit, 24-bit, 32-bit就指的是bit depth，显然bit depth越高，振幅的表示越精确。比特率bit rate = sample rate * bit depth，即每秒用多少bit来表示音频数据。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cmbbq.github.io/img/audio1.png&#34; alt=&#34;audio1&#34;&gt;&lt;/p&gt;
&lt;p&gt;PGC和UGC的差别主要是信噪比，毕竟录音的时候连手机都不能带，空调、电灯都可能影响波形电平稳定。UGC可以想象，直播或者念稿子，噪声的平均振幅往往还比背景音乐更大。音频从32bit到16bit是一个量化的过程，不过无论采样精度多高，都终归是对现实的一个量化，量化error引入量化噪声，所以任何数字音频都是有底噪的——白噪声在各频率上都是一样的能量，由于能量（响度）较低，被称为noise floor，表现为微弱的嘶嘶声。&lt;/p&gt;
&lt;p&gt;音频时域数据的纵坐标为振幅，横坐标为时间，可绘制成波形图——其震动频率决定音高，平均振幅决定响度，具体波形和这种其他因素决定音色。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cmbbq.github.io/img/wave.jpeg&#34; alt=&#34;wave&#34;&gt;&lt;/p&gt;
&lt;p&gt;时域与频域是对信号波的两个观察面。时域是真实世界唯一存在的域，频域则是对时域的数学构造。任何时域信号都可以表示为不同频率的正弦波信号的叠加。&lt;/p&gt;
&lt;p&gt;常见的音频格式包括wav、mdi、mp3、mp3pro、wma、realaudio、audible、aac、ogg vorbis、ape、flac。不同的音频编码有不同的目标，在压缩（降低传输所需信道带宽）和质量（对人耳来说）之间做tradeoff。&lt;/p&gt;
&lt;p&gt;各种格式的数字音频都能转成采样率8000Hz的PCM格式音频，PCM(pulse code modulation)是最简单的时域编码方式，就是对信号的离散和量化（通常是对数量化）。1/8000s长度的帧即构成了PCM音频在时域上的最小单位，每个帧包含channel数目个采样点，如果channel数目为1，则帧大小就等于bit depth。我们可以把PCM音频切分成多个chunk，每个chunk有固定大小（比如包含1024个帧），chunk与chunk之间必须有重合（比如256个帧）。之所以要有些重合，是为了对抗Time Skew（假如不做重合，查询音频的chunk的起始帧和库中的音频各个chunk的起始帧有一定offset就查询不到了）。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cmbbq.github.io/img/timeskew.png&#34; alt=&#34;ts&#34;&gt;&lt;/p&gt;
&lt;p&gt;接下来只需对各个chunk进行1维离散傅立叶变换（fftw_plan_dft_1d）就能得到各个chunk的频域信息（如下图，横坐标为频率，纵坐标为能量）。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cmbbq.github.io/img/spec.png&#34; alt=&#34;sp&#34;&gt;&lt;/p&gt;
&lt;p&gt;再将这些帧的频谱按时间顺序拼起来（可以有一些重合）就形成一个y轴为频率，x轴为时间，z轴为能量的三维表面（也可以用平面彩图表示，z轴的高度换成色彩来表示能量），这就形成了频谱图（spectrogram）。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cmbbq.github.io/img/spec2.png&#34; alt=&#34;sp&#34;&gt;
&lt;img src=&#34;https://cmbbq.github.io/img/spec3.png&#34; alt=&#34;sp&#34;&gt;&lt;/p&gt;
&lt;p&gt;有了频谱图，就可以尝试从较长的数据中提炼出简短的信息作为这段音频的指纹了。在频谱图上可以逐帧找到各帧上显著的高能频率点（salient peaks，能量超过一定阈值，且比周围所有点都高）——这些点本身已经可以作为音频的指纹特征了，只是不够鲁棒，因为点与点之间是无关的，满屏都是噪点的情况下就会有误匹配。一个改进方案是这些点右侧划定一个目标区域，在区域内找出一些点，形成几个pair，这些pair叫做landmark特征，即[t1, f1, t2, f2]，其抗噪能力增强了很多。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cmbbq.github.io/img/spec4.png&#34; alt=&#34;sp&#34;&gt;&lt;/p&gt;
</content>
    </item>
    
  </channel>
</rss>
