<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>music computing on Cmbbq&#39;s Encyclopedia</title>
    <link>https://cmbbq.github.io/tags/music-computing/</link>
    <description>Recent content in music computing on Cmbbq&#39;s Encyclopedia</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 06 Feb 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://cmbbq.github.io/tags/music-computing/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Music Signal Processing</title>
      <link>https://cmbbq.github.io/posts/music-signal-processing/</link>
      <pubDate>Thu, 06 Feb 2025 00:00:00 +0000</pubDate>
      
      <guid>https://cmbbq.github.io/posts/music-signal-processing/</guid>
      <description>MP3/AAC -&amp;gt; PCM 音频的数字表示多种多样，抖t等平台存储的多媒体数据往往是MP3、AAC、OGG等有损格式，它们基于心理学模型去除人耳不敏感的音频信号从而大幅压缩文件体积1。
这些压缩格式固然对存储、传输友好，但想对它们进行计算，还是需转成PCM。
PCM的数据格式简单，去掉header后就可以将其视作能量2数组（vec），数组下标即time frames。
PCM -&amp;gt; STFT -&amp;gt; Spectrogram PCM音频样本经过短时傅里叶变换（STFT）可得时频图，即spectrogram（vec&amp;lt;vec&amp;gt;）。
STFT将信号分为多个时间窗口，对每个窗口内的信号逐一乘以窗口函数（如汉明窗3），并施加DFT。
STFT的关键参数n_fft（记作$N$）即时间窗口的帧数，其本质是调节频谱分辨率和时间分辨率的参数。将采样率4记为$S$，则$频谱分辨率 = \frac{S}{N}$，$窗口时长 = \frac{N}{S}$。
因此n_fft越高，采样率越高，频率分辨率越高（频段越细）。在语音识别中往往n_fft = 512就够用，在音乐分析中，则往往需要2048才能解析低频声乐，如鼓声、贝斯。
此外，n_fft越高，时间分辨率越低（窗口时长更长，时间定位更不精确），因此语音、打击乐等瞬态信号处理场景更适合用低n_fft。
STFT得到的时频图的频域单位是bin index（频率分量索引，记作$k$），稍作换算即可得到声音的频率$f$(单位Hz)：$f = \frac{k* S}{N}$。
Spectrogram -&amp;gt; Mel Filter Bank -&amp;gt; Mel Spectrogram 相比的时频图频率轴默认的线性标度，梅尔频率提供了一种更符合人耳频率感知的非线性标度：
构造梅儿滤波器组常见的做法是：
确定频率范围，通常为0到奈奎斯特频率（采样率的一半，例如16kHz音频对应8kHz）。 根据$M(f) = 2595 \log_{10}(1 + \frac{f}{700})$将线性刻度映射到梅尔刻度。 在梅尔刻度上等间距划分M个频带（如128个5），再转换回线性频率，得到每个频带的中心频率。 每个滤波器在频域呈三角形，覆盖相邻中心频率的范围，峰值位于当前频带的中心频率。 将每个三角滤波器与频谱图的能量分布相乘并求和，得到各梅尔频带的能量。最终，每个时间帧的频谱被压缩为M维的梅尔频谱特征。
MFCC(Mel-Frequency Cepstral Coefficients) 梅尔频谱的每一列做DCT(Discrete Cosine Transform)。 DCT 将输入信号分解为一系列不同频率的余弦分量。 其中低频分量对应信号的整体趋势，高频分量对应信号的细节和噪声。
通常只取前面若干个低频DCT系数作为MFCC特征，因为高频系数混沌一片，意义不大，而低频系数可刻画乐器的音色、语音的音素。
MFCC丢弃了相当多频谱细节，更适合语音识别，而非音乐分析。
CQT(Constant-Q Transform) CQT保证所有频点的Q值相同，即$Q=\frac{f}{\Delta f}$ 恒定，因此比梅尔谱更极端地保障了“低频区分辨率高，高频区分辨率低”的特性。CQT频率按指数分布（如钢琴的88个键对应88个频点），每个八度（octave）包含固定数量的频点（如12个半音），不仅更符合人耳听觉特性，也更符合乐理，适合捕捉音乐信号的谐波结构和音高变化。
CQT的缺点是计算效率低，缺完美信号重构的逆变换。
Spectrogram -&amp;gt; Hopping -&amp;gt; Overlapping Chunks 小步长重叠切分通过增加时间轴上的匹配候选密度，使系统能够容忍时间偏移(time skew)6。这是音乐检索领域对抗时间对齐问题的经典策略。</description>
      <content>&lt;h2 id=&#34;mp3aac---pcm&#34;&gt;MP3/AAC -&amp;gt; PCM&lt;/h2&gt;
&lt;p&gt;音频的数字表示多种多样，抖t等平台存储的多媒体数据往往是MP3、AAC、OGG等有损格式，它们基于心理学模型去除人耳不敏感的音频信号从而大幅压缩文件体积&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;。&lt;/p&gt;
&lt;p&gt;这些压缩格式固然对存储、传输友好，但想对它们进行计算，还是需转成PCM。&lt;/p&gt;
&lt;p&gt;PCM的数据格式简单，去掉header后就可以将其视作能量&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;数组（vec&lt;f32&gt;），数组下标即time frames。&lt;/p&gt;
&lt;h2 id=&#34;pcm---stft---spectrogram&#34;&gt;PCM -&amp;gt; STFT -&amp;gt; Spectrogram&lt;/h2&gt;
&lt;p&gt;PCM音频样本经过短时傅里叶变换（STFT）可得时频图，即spectrogram（vec&amp;lt;vec&lt;float&gt;&amp;gt;）。&lt;/p&gt;
&lt;p&gt;STFT将信号分为多个时间窗口，对每个窗口内的信号逐一乘以窗口函数（如汉明窗&lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;），并施加DFT。&lt;/p&gt;
&lt;p&gt;STFT的关键参数n_fft（记作$N$）即时间窗口的帧数，其本质是调节频谱分辨率和时间分辨率的参数。将采样率&lt;sup id=&#34;fnref:4&#34;&gt;&lt;a href=&#34;#fn:4&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;4&lt;/a&gt;&lt;/sup&gt;记为$S$，则$频谱分辨率 = \frac{S}{N}$，$窗口时长 = \frac{N}{S}$。&lt;/p&gt;
&lt;p&gt;因此n_fft越高，采样率越高，频率分辨率越高（频段越细）。在语音识别中往往n_fft = 512就够用，在音乐分析中，则往往需要2048才能解析低频声乐，如鼓声、贝斯。&lt;/p&gt;
&lt;p&gt;此外，n_fft越高，时间分辨率越低（窗口时长更长，时间定位更不精确），因此语音、打击乐等瞬态信号处理场景更适合用低n_fft。&lt;/p&gt;
&lt;p&gt;STFT得到的时频图的频域单位是bin index（频率分量索引，记作$k$），稍作换算即可得到声音的频率$f$(单位Hz)：$f = \frac{k* S}{N}$。&lt;/p&gt;
&lt;h2 id=&#34;spectrogram---mel-filter-bank---mel-spectrogram&#34;&gt;Spectrogram -&amp;gt; Mel Filter Bank -&amp;gt; Mel Spectrogram&lt;/h2&gt;
&lt;p&gt;相比的时频图频率轴默认的线性标度，梅尔频率提供了一种更符合人耳频率感知的非线性标度：&lt;/p&gt;
&lt;p&gt;构造梅儿滤波器组常见的做法是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;确定频率范围，通常为0到奈奎斯特频率（采样率的一半，例如16kHz音频对应8kHz）。&lt;/li&gt;
&lt;li&gt;根据$M(f) = 2595 \log_{10}(1 + \frac{f}{700})$将线性刻度映射到梅尔刻度。&lt;/li&gt;
&lt;li&gt;在梅尔刻度上等间距划分M个频带（如128个&lt;sup id=&#34;fnref:5&#34;&gt;&lt;a href=&#34;#fn:5&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;5&lt;/a&gt;&lt;/sup&gt;），再转换回线性频率，得到每个频带的中心频率。&lt;/li&gt;
&lt;li&gt;每个滤波器在频域呈三角形，覆盖相邻中心频率的范围，峰值位于当前频带的中心频率。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;将每个三角滤波器与频谱图的能量分布相乘并求和，得到各梅尔频带的能量。最终，每个时间帧的频谱被压缩为M维的梅尔频谱特征。&lt;/p&gt;
&lt;h2 id=&#34;mfccmel-frequency-cepstral-coefficients&#34;&gt;MFCC(Mel-Frequency Cepstral Coefficients)&lt;/h2&gt;
&lt;p&gt;梅尔频谱的每一列做DCT(Discrete Cosine Transform)。
DCT 将输入信号分解为一系列不同频率的余弦分量。
其中低频分量对应信号的整体趋势，高频分量对应信号的细节和噪声。&lt;/p&gt;
&lt;p&gt;通常只取前面若干个低频DCT系数作为MFCC特征，因为高频系数混沌一片，意义不大，而低频系数可刻画乐器的音色、语音的音素。&lt;/p&gt;
&lt;p&gt;MFCC丢弃了相当多频谱细节，更适合语音识别，而非音乐分析。&lt;/p&gt;
&lt;h2 id=&#34;cqtconstant-q-transform&#34;&gt;CQT(Constant-Q Transform)&lt;/h2&gt;
&lt;p&gt;CQT保证所有频点的Q值相同，即$Q=\frac{f}{\Delta f}$ 恒定，因此比梅尔谱更极端地保障了“低频区分辨率高，高频区分辨率低”的特性。CQT频率按指数分布（如钢琴的88个键对应88个频点），每个八度（octave）包含固定数量的频点（如12个半音），不仅更符合人耳听觉特性，也更符合乐理，适合捕捉音乐信号的谐波结构和音高变化。&lt;/p&gt;
&lt;p&gt;CQT的缺点是计算效率低，缺完美信号重构的逆变换。&lt;/p&gt;
&lt;h2 id=&#34;spectrogram---hopping---overlapping-chunks&#34;&gt;Spectrogram -&amp;gt; Hopping -&amp;gt; Overlapping Chunks&lt;/h2&gt;
&lt;p&gt;小步长重叠切分通过增加时间轴上的匹配候选密度，使系统能够容忍时间偏移(time skew)&lt;sup id=&#34;fnref:6&#34;&gt;&lt;a href=&#34;#fn:6&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;6&lt;/a&gt;&lt;/sup&gt;。这是音乐检索领域对抗时间对齐问题的经典策略。&lt;/p&gt;
&lt;p&gt;一种可行的做法是将mel spectrogram以1/4个chunk size为hop size切分成overlapping chunks，再进行后续处理——可以是某种深度音乐模型，也可以是基于规则的audio fingerprinting。&lt;/p&gt;
&lt;h2 id=&#34;shazam-audio-fingerprinting&#34;&gt;Shazam Audio Fingerprinting&lt;/h2&gt;
&lt;p&gt;在原曲或录音歌曲匹配中，linear spectrogram要比mel spectrogram更好，因为录音设备的音高误差是沿着线性频率轴（Hz）均匀分布的，并不是沿着梅尔刻度频率分量轴均匀分布的。此外linear spectrogram保留更多的高频音乐信号，如果用mel spectrogram就会少很多高频区域特征，令高频区域特征不够精确。&lt;/p&gt;
&lt;p&gt;若指纹stft以1024作为fft window，512作为fft hop&lt;sup id=&#34;fnref:7&#34;&gt;&lt;a href=&#34;#fn:7&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;7&lt;/a&gt;&lt;/sup&gt;，在8000Hz PCM上施加STFT，每个hop（peaks帧=半个fft帧）找一次频谱peaks，因此从peak时间帧单位包含512样本，即$512/8000 = 0.064$s。9bits的peaks时间帧就可以表示32.768s，这是Δt的上限，t1分配13bits即可表示接近9分钟的时长，覆盖大多数pgc音乐时长。正频率分量数目为$\frac{1024}{2} = 512$，每个频率分量代表一个频率区间，频带宽7.8125Hz（采样率8000Hz对应的频域范围是0~4000Hz）。&lt;/p&gt;
&lt;p&gt;Δf,f1,Δt一共只需要27bits(padded to 32bits)，再加上t1的32bits，即构成了64bits fingerprint(hash:t1)，在此基础上构建hashmap，建立hash到postinglist(docid:t1的序列)的映射，即可迅速定位指纹出现在哪个doc的哪个时间。若t1用13bits表示，则docid可用19bits表示，从而刚好对齐到32bits，19bits可表示524288个docid，因此Shazam常用库粒度即为524288。&lt;/p&gt;
&lt;div class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;
&lt;p&gt;压缩率可达原始PCM音频的$\frac{1}{10}$~$\frac{1}{12}$。&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34;&gt;
&lt;p&gt;音频信号语境下，能量即振幅，与响度相关的换算公式是：$L_{db} = 10 \log_{10}(E)$。&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:3&#34;&gt;
&lt;p&gt;汉明窗让信号在时域上更平滑，减少窗口边界处的信号突变，让更多能量集中在窗口中心，减少边缘的频谱泄露，缓解栅栏效应。所谓栅栏效应（即频谱泄漏）是在信号处理中由于信号在时域上的截断而导致的频谱分析中频率分辨率不足的现象。&amp;#160;&lt;a href=&#34;#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:4&#34;&gt;
&lt;p&gt;每秒样本数，单位Hz。&amp;#160;&lt;a href=&#34;#fnref:4&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:5&#34;&gt;
&lt;p&gt;128个梅尔频率带对人耳来说，频率分辨率足够，计算负担也不会太高。&amp;#160;&lt;a href=&#34;#fnref:5&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:6&#34;&gt;
&lt;p&gt;所谓time skew（时间偏移）指的是同一段音乐在不同录音或播放中存在的时间上的微小差异，比如同一首歌的不同版本可能开始时间不同，或者在录制时存在延迟，这可能导致直接匹配时无法对齐，从而影响检索的准确性。&amp;#160;&lt;a href=&#34;#fnref:6&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:7&#34;&gt;
&lt;p&gt;为了对抗time skew，实际上还会再额外引入1/4个hop size作为步长，更细粒度地做hopping，但stft的重叠仍然是选择50%。细粒度的额外3个time shift则生成另外3个spectrogram。&amp;#160;&lt;a href=&#34;#fnref:7&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</content>
    </item>
    
  </channel>
</rss>
